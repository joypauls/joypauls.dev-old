---
title: "Control & Reinforcement: Complimentary Perspectives"
description: Control theory from the perspective of data science.
date: 2021-12-02
tags:
  - Math
  - Python
---


When I was a student, I was very interested in designing systems with *feedback loops*. I was learning about dynamical systems and 
some machine learning, but rarely did anyone mention the elephant in the room for real-world systems: feedback! 


## Control Theory


## Reinforcement Learning



I find that one of the best ways to understand why certain fields look the way they do is by listening to the problems 
that they are trying to solve. Why was this particular set of methods developed and why did it form a cohesive 
subfield? Often, we can clearly see by learning about the problems the practitioners try to solve.


part of the difference is historical.



----

## Curse of Dimensionality

When studying statistical modelling from a computational perspective, we are usually introduced early on to the 
so-called **curse of dimensionality** as a pitfall for practitioners new to the topic. 


## Volumes in Higher Dimensions

Let's take a look at a simple illustration of where our intuition begins to fail us in high dimensions[^2]. 
We start with the unit interval, 
and highlight a subinterval with one endpoint at $0$ and the other at $\frac{1}{2}$. We can see clearly that the highlighted interval is
$\frac{1}{2}$ of the total length. Easy enough? 

Now let's move on to 2 dimensions, and consider a square with sides of unit length. Extending the experiment, we highlight the square region 
covered from $(0,0)$ to $(0,\frac{1}{2})$ and $(0,0)$ to $(\frac{1}{2},0)$. This time, the highlighted area covers $\frac{1}{4}$ of the total area.

In 3 dimensions, we can now see the pattern. The highlighted volume only accounts for $\frac{1}{8}$ of the total volume of the unit cube.


[^1]: Sutton and Barto. *Reinforcement Learning: An Introduction*. Springer, 2014. 

